{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MindBridge Task Assignment Prototype\n",
    "\n",
    "This notebook demonstrates how to automate the assignment of review tasks in MindBridge using the MindBridge API. It covers:\n",
    "\n",
    "- Connecting to a MindBridge analysis and exporting filtered data.\n",
    "- Assigning tasks to specific users based on data attributes.\n",
    "\n",
    "Use this notebook as a template for integrating MindBridge task assignment into your audit workflows."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Installing the MindBridge API Python Client\n",
    "\n",
    "This must be the first code cell executed in the notebook to ensure the [MindBridge API Python Client](https://pypi.org/project/mindbridge-api-python-client/) is available for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c1d39c-34f8-44d2-8d79-89c486725ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade mindbridge-api-python-client\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Configuration\n",
    "\n",
    "Set up the configuration parameters for connecting to the MindBridge analysis and defining the task assignment logic. Here are the variables available to be configured:\n",
    "\n",
    "- `analysis_url`: The URL of the MindBridge analysis from which to export data. In a later cell this is parsed to extract the analysis result ID and the MindBridge server URL. In many cases you may want to run this immediately after and analysis run, so you may alternatively determine these as part of that process.\n",
    "- `data_table_query`: A dictionary defining the query to filter the data table rows for which tasks will be created.\n",
    "- `data_table_logical_name`: The logical name of the data table to export data from (e.g., \"gl_journal_lines\").\n",
    "- `column_for_assigning`: The column name in the data table used to determine task assignment.\n",
    "- `assigned_user_map`: A mapping of `column_for_assigning` values to MindBridge user email addresses for task assignment.\n",
    "- `MINDBRIDGE_API_TOKEN` secret scope must be created in Databricks containing a valid MindBridge API token. For more details see the first notebook in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407a087f-571e-4acf-94f8-1e38711de33f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "analysis_url = \"https://psus.mindbridge.ai/app/organization/68f7dc86efccc75265245b0e/engagement/68f7dc87efccc75265245b10/analysis/68f7dc9eefccc75265245bf4/analyze/financial-statements?productCode=GENERAL_LEDGER#facetBarState=JTdCJTIydmlzaWJsZV9mYWNldF9pZHMlMjIlM0ElNUIlNUQlMkMlMjJmYWNldF9zdGF0ZXMlMjIlM0ElNUIlNUQlN0Q=\"\n",
    "data_table_query = {\n",
    "    \"effective_date\": {\"$gte\": date(2022, 4, 1), \"$lt\": date(2022, 6, 1)},\n",
    "    \"risk\": {\"$gte\": 15_00},\n",
    "}\n",
    "data_table_logical_name = \"gl_journal_lines\"\n",
    "column_for_assigning = \"company_code\"\n",
    "assigned_user_map = {\n",
    "    \"122644\": \"kevin.paulson@mindbridge.ai\",\n",
    "    \"8477\": \"michelle.alexander@mindbridge.ai\",\n",
    "}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Processing\n",
    "\n",
    "All cells after this point perform the task assignment process, they wouldn't typically require modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401879bc-632c-4bf6-a47c-e156a4e540d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from urllib3.util import parse_url\n",
    "\n",
    "parsed_url = parse_url(analysis_url)\n",
    "mindbridge_url = parsed_url.host\n",
    "\n",
    "parsed_url_path = parsed_url.path.split(\"/\")\n",
    "analysis_result_id = parsed_url_path[parsed_url_path.index(\"analysis\") + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "392f5983-f50e-4cf0-a9cd-99bec71e940e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mindbridgeapi as mbapi\n",
    "\n",
    "# Load your token from the secret scope\n",
    "token = dbutils.secrets.get(\n",
    "    scope=\"mindbridge-api-tutorials\", key=\"MINDBRIDGE_API_TOKEN\"\n",
    ")\n",
    "\n",
    "# Create a connection to the server\n",
    "server = mbapi.Server(url=mindbridge_url, token=token)\n",
    "\n",
    "# Get the analysis\n",
    "analysis_result = server.analysis_results.get_by_id(analysis_result_id)\n",
    "analysis = server.analyses.get_by_id(analysis_result.analysis_id)\n",
    "\n",
    "print(\"Available data tables:\")\n",
    "for x in analysis.data_tables:\n",
    "    print(f\"- logical_name: {x.logical_name} (type: {x.type}, id: {x.id})\")\n",
    "\n",
    "server.analyses.restart_data_tables(analysis)\n",
    "data_table = next(\n",
    "    x for x in analysis.data_tables if x.logical_name == data_table_logical_name\n",
    ")\n",
    "print(\n",
    "    f\"Using logical_name: {data_table.logical_name} (type: {data_table.type}, id: {data_table.id})\"\n",
    ")\n",
    "\n",
    "assigned_user_map_id = {}\n",
    "for key, assigned_user_email in assigned_user_map.items():\n",
    "    user, *others = server.users.get(json={\"email\": assigned_user_email})\n",
    "    if not user:\n",
    "        raise ValueError(f\"User with email {assigned_user_email} not found\")\n",
    "\n",
    "    if others:\n",
    "        raise Exception(\n",
    "            f\"Unexpected error: multiple users found with email {assigned_user_email}\"\n",
    "        )\n",
    "\n",
    "    assigned_user_map_id[key] = user.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae23e9a0-ec79-4e8f-b412-ff84a1761d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import NamedTemporaryFile\n",
    "import csv\n",
    "\n",
    "with NamedTemporaryFile(delete=False) as temp_file:\n",
    "    temp_file_path = Path(temp_file.name)\n",
    "\n",
    "print(f\"Exporting to: {temp_file_path}\")\n",
    "async_result = server.data_tables.export(\n",
    "    data_table,\n",
    "    fields=[\"rowid\", \"txid\", \"risk\", \"effective_date\", column_for_assigning],\n",
    "    query=data_table_query,\n",
    ")\n",
    "server.data_tables.wait_for_export(async_result)\n",
    "temp_file_path = server.data_tables.download(\n",
    "    async_result, output_file_path=temp_file_path\n",
    ")\n",
    "\n",
    "with temp_file_path.open(newline=\"\", encoding=\"utf_8\") as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    print(\"Creating Tasks for:\")\n",
    "    for row in reader:\n",
    "        row_id = row[\"rowid\"]\n",
    "        transaction_id = row[\"txid\"]\n",
    "        print(\n",
    "            f\"- row_id: {row_id}, transaction_id: {transaction_id}, risk: {row['risk']}, effective_date: {row['effective_date']}\"\n",
    "        )\n",
    "        assigned_id = assigned_user_map_id[row[column_for_assigning]]\n",
    "        task = mbapi.TaskItem(\n",
    "            row_id=row_id,\n",
    "            transaction_id=transaction_id,\n",
    "            type=mbapi.TaskType.ENTRY,\n",
    "            status=mbapi.TaskStatus.OPEN,\n",
    "            engagement_id=analysis.engagement_id,\n",
    "            analysis_result_id=analysis_result.id,\n",
    "            audit_areas=[\"Audit Area 1\"],\n",
    "            assigned_id=assigned_id,\n",
    "        )\n",
    "        existing_task = next(\n",
    "            server.tasks.get(\n",
    "                json={\n",
    "                    \"analysisId\": analysis.id,\n",
    "                    \"analysisResultId\": task.analysis_result_id,\n",
    "                    \"transactionId\": task.transaction_id,\n",
    "                    \"rowId\": task.row_id,\n",
    "                }\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if existing_task:\n",
    "            print(f\"   - Task already exists as {existing_task.id}\")\n",
    "        else:\n",
    "            task = server.tasks.create(task)\n",
    "            print(f\"    - Created task: {task.id}\")\n",
    "\n",
    "print(\"Done.\")\n",
    "temp_file_path.unlink()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 616437765715387,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "7_Task_Assignment_Prototype",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
