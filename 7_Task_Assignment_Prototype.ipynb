{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55d5ae82-8e05-4034-bbab-03d5fcc921d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Integrating MindBridge with Databricks: A Step-by-Step Guide\n",
    "This tutorial will guide you through the process of integrating MindBridge with Databricks. We will walkthrough how to set up an Organization and Engagement using the MindBridge SDK, how to perform a General Ledger Analysis on data from Databricks, then how you can extract key information from your Analysis Results. Here's what we'll cover:\n",
    "\n",
    "1. **Installing the MindBridge SDK in Databricks**  \n",
    "   We'll start by installing the MindBridge SDK in your Databricks environment, enabling access to MindBridge's API features within your notebooks.\n",
    "\n",
    "2. **Storing your MindBridge API Token in Databricks**  \n",
    "   Learn to securely save your MindBridge API token in a Databricks-backed secret scope. This step ensures that sensitive credentials are safely managed within Databricks.\n",
    "\n",
    "3. **Loading your MindBridge API Token in Databricks**  \n",
    "   With the token stored, we'll show you how to load and use it to configure your API connection.\n",
    "\n",
    "4. **Setting Up an Organization and Engagement**  \n",
    "   Here, you'll learn how to configure an Organization and Engagement for your Analysis.\n",
    "\n",
    "5. **Uploading Files to the File Manager**  \n",
    "   How to upload files into the File Manager created for your Engagement\n",
    "\n",
    "6. **Creating and Running Analyses**  \n",
    "   In this section, you'll learn how to create a new analysis, link the necessary data from the File Manager, and execute the analysis.\n",
    "\n",
    "7. **Getting the Analysis Results**  \n",
    "   Finally, we'll retrieve and display the results of your analysis, providing insights into your data that you can further leverage within Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a221f5c1-5e69-4dfd-a142-38b09d420edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Installing the MindBridge SDK in Databricks\n",
    "The following commands can be run to install the [mindbridge-api-python-client](https://pypi.org/project/mindbridge-api-python-client/) to your currently selected cluster. Version 1.5.1 or newer is required for the steps in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c1d39c-34f8-44d2-8d79-89c486725ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade mindbridge-api-python-client pydantic<2.12\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407a087f-571e-4acf-94f8-1e38711de33f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "analysis_url = \"https://psus.mindbridge.ai/app/organization/68f7dc86efccc75265245b0e/engagement/68f7dc87efccc75265245b10/analysis/68f7dc9eefccc75265245bf4/analyze/financial-statements?productCode=GENERAL_LEDGER#facetBarState=JTdCJTIydmlzaWJsZV9mYWNldF9pZHMlMjIlM0ElNUIlNUQlMkMlMjJmYWNldF9zdGF0ZXMlMjIlM0ElNUIlNUQlN0Q=\"\n",
    "data_table_query = {\n",
    "    \"effective_date\": {\"$gte\": date(2022, 5, 1), \"$lt\": date(2022, 6, 1)},\n",
    "    \"risk\": {\"$gte\": 3_000},\n",
    "}\n",
    "\n",
    "assigned_user_email = \"kevin.paulson@mindbridge.ai\"\n",
    "data_table_logical_name = \"gl_journal_lines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fd13672-8bc9-45ae-a5d1-94d985e4a0ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Storing Your MindBridge API Token in Databricks\n",
    "If you do not have an API Token already you can follow [Create an API token](https://support.mindbridge.ai/hc/en-us/articles/9349943782039-Create-an-API-token) on our knowledge base. Once that is done, we'll [Create a Databricks-backed secret scope](https://learn.microsoft.com/en-us/azure/databricks/security/secrets/#create-a-databricks-backed-secret-scope) using the Databricks CLI to securely store your token. If you haven't set up the Databricks CLI yet, you can follow [Install or update the Databricks CLI](https://learn.microsoft.com/en-us/azure/databricks/dev-tools/cli/install).\n",
    "\n",
    "After installing and configuring the CLI, use the following commands to create a new secret scope and add your API Token to the scope:\n",
    "\n",
    "```sh\n",
    "# Create the secret scope named \"mindbridge-api-tutorials\"\n",
    "databricks secrets create-scope mindbridge-api-tutorials\n",
    "\n",
    "# Add your MindBridge API Token to the scope\n",
    "databricks secrets put-secret mindbridge-api-tutorials MINDBRIDGE_API_TOKEN\n",
    "```\n",
    "\n",
    "Once your token is added, you can verify its existence by running the following:\n",
    "```sh\n",
    "databricks secrets list-scopes\n",
    "databricks secrets list-secrets mindbridge-api-tutorials\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401879bc-632c-4bf6-a47c-e156a4e540d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from urllib3.util import parse_url\n",
    "\n",
    "parsed_url = parse_url(analysis_url)\n",
    "mindbridge_url = parsed_url.host\n",
    "\n",
    "parsed_url_path = parsed_url.path.split(\"/\")\n",
    "analysis_result_id = parsed_url_path[parsed_url_path.index(\"analysis\") + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "109a403a-ae91-4d2d-a0f7-89f9434dfacc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Loading your MindBridge API Token in Databricks\n",
    "\n",
    "In this section, we'll load the MindBridge API token securely stored in Databricks and configure the API connection. Replace the ```url``` with the url for your MindBridge instance. Upon execution, you should see details about the user associated with your token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "392f5983-f50e-4cf0-a9cd-99bec71e940e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mindbridgeapi as mbapi\n",
    "\n",
    "# Load your token from the secret scope\n",
    "token = dbutils.secrets.get(\n",
    "    scope=\"mindbridge-api-tutorials\", key=\"MINDBRIDGE_API_TOKEN\"\n",
    ")\n",
    "\n",
    "# Create a connection to the server\n",
    "server = mbapi.Server(url=mindbridge_url, token=token)\n",
    "\n",
    "# Get the analysis\n",
    "analysis_result = server.analysis_results.get_by_id(analysis_result_id)\n",
    "analysis = server.analyses.get_by_id(analysis_result.analysis_id)\n",
    "\n",
    "print(\"Available data tables:\")\n",
    "for x in analysis.data_tables:\n",
    "    print(f\"- logical_name: {x.logical_name} (type: {x.type}, id: {x.id})\")\n",
    "\n",
    "server.analyses.restart_data_tables(analysis)\n",
    "data_table = next(\n",
    "    x for x in analysis.data_tables if x.logical_name == data_table_logical_name\n",
    ")\n",
    "print(\n",
    "    f\"Using logical_name: {data_table.logical_name} (type: {data_table.type}, id: {data_table.id})\"\n",
    ")\n",
    "\n",
    "user, *others = server.users.get(json={\"email\": assigned_user_email})\n",
    "if not user:\n",
    "    raise ValueError(f\"User with email {assigned_user_email} not found\")\n",
    "\n",
    "if others:\n",
    "    raise Exception(\n",
    "        f\"Unexpected error: multiple users found with email {assigned_user_email}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae23e9a0-ec79-4e8f-b412-ff84a1761d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import NamedTemporaryFile\n",
    "import csv\n",
    "\n",
    "with NamedTemporaryFile(delete=False) as temp_file:\n",
    "    temp_file_path = Path(temp_file.name)\n",
    "\n",
    "print(f\"Exporting to: {temp_file_path}\")\n",
    "async_result = server.data_tables.export(\n",
    "    data_table,\n",
    "    fields=[\"rowid\", \"txid\", \"risk\", \"effective_date\"],\n",
    "    query=data_table_query,\n",
    ")\n",
    "server.data_tables.wait_for_export(async_result)\n",
    "temp_file_path = server.data_tables.download(\n",
    "    async_result, output_file_path=temp_file_path\n",
    ")\n",
    "\n",
    "with temp_file_path.open(newline=\"\", encoding=\"utf_8\") as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    print(\"Creating Tasks for:\")\n",
    "    for row in reader:\n",
    "        row_id = row[\"rowid\"]\n",
    "        transaction_id = row[\"txid\"]\n",
    "        print(\n",
    "            f\"- row_id: {row_id}, transaction_id: {transaction_id}, risk: {row['risk']}, effective_date: {row['effective_date']}\"\n",
    "        )\n",
    "        task = mbapi.TaskItem(\n",
    "            row_id=row_id,\n",
    "            transaction_id=transaction_id,\n",
    "            type=mbapi.TaskType.ENTRY,\n",
    "            status=mbapi.TaskStatus.OPEN,\n",
    "            engagement_id=analysis.engagement_id,\n",
    "            analysis_result_id=analysis_result.id,\n",
    "            audit_areas=[\"Audit Area 1\"],\n",
    "            assigned_id=user.id,\n",
    "        )\n",
    "        task = server.tasks.create(task)\n",
    "\n",
    "print(\"Done.\")\n",
    "temp_file_path.unlink()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 616437765715387,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "7_Task_Assignment_Prototype",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
